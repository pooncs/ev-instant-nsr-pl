name: nerf-blender-${dataset.scene}
tag: ''
seed: 42

dataset:
  name: evdata
  scene: ???
  root_dir: /home/ubuntu/src/data/${dataset.scene}
  #img_wh:
  #  - 800
  #  - 800
  img_downscale: 1 # specify training image size by either img_wh or img_downscale
  near_plane: 5.0
  far_plane: 15.0
  load_data_on_gpu: false
  spheric_poses: false
  use_pixel_centers: true
  train_split: 'train'
  val_split: 'val'
  test_split: 'test'

model:
  name: nerf
  radius: 1
  num_samples_per_ray: 1024
  train_num_rays: 256
  max_train_num_rays: 65536
  grid_prune: true
  dynamic_ray_sampling: true
  batch_image_sampling: true
  randomized: true
  ray_chunk: 65536
  learned_background: false
  background_color: random
  geometry:
    name: volume-density
    radius: ${model.radius}
    feature_dim: 16
    density_activation: trunc_exp
    density_bias: -1
    isosurface:
      method: mc
      resolution: 256
      chunk: 2097152
      threshold: 5.0
    xyz_encoding_config:
      otype: HashGrid
      n_levels: 16
      n_features_per_level: 2
      log2_hashmap_size: 19
      base_resolution: 16
      per_level_scale: 1.447269237440378  
    mlp_network_config:
      otype: FullyFusedMLP
      activation: ReLU
      output_activation: none
      n_neurons: 64
      n_hidden_layers: 1
  texture:
    name: volume-radiance
    input_feature_dim: ${model.geometry.feature_dim}
    dir_encoding_config:
      otype: SphericalHarmonics
      degree: 4    
    mlp_network_config:
      otype: FullyFusedMLP
      activation: ReLU
      output_activation: Sigmoid
      n_neurons: 64
      n_hidden_layers: 2
  pose_refine:
    name: pose_refine
    num_cameras: ???
    mode: none
    position_noise_std: 0.0
    orientation_noise_std: 0.0

system:
  name: nerf-system
  loss:
    lambda_rgb: 1.
    lambda_distortion: 0.01
  optimizer:
    name: Adam
    args:
      lr: 0.01
      betas: [0.9, 0.99]
      eps: 1.e-15
    params:
      geometry:
          lr: 0.01
      texture:
          lr: 0.01
      pose_refine:
          lr: 0.0006
  warmup_steps: 500
  scheduler:
    name: SequentialLR
    interval: step
    milestones:
      - ${system.warmup_steps}
    schedulers:
      - name: LinearLR # linear warm-up in the first system.warmup_steps steps
        args:
          start_factor: 0.01
          end_factor: 1.0
          total_iters: ${system.warmup_steps}
      - name: ExponentialLR
        args:
          gamma: ${calc_exp_lr_decay_rate:0.1,${sub:${trainer.max_steps},${system.warmup_steps}}}

checkpoint:
  save_top_k: -1
  every_n_train_steps: ${trainer.max_steps}

trainer:
  max_steps: 30000
  log_every_n_steps: 200
  num_sanity_val_steps: 0
  val_check_interval: 10000
  enable_progress_bar: true 
  precision: 16